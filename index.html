
<!DOCTYPE html>
<html>

  <head>
<!--    <meta http-equiv="refresh" content="0;url=http://graduatestudents.ucmerced.edu/wlai24/" /> -->
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="kaiwang960112.github.io : ">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="kpzhang">
    <link rel="stylesheet" href="./src/main.css">
    <link rel="stylesheet" href="./src/bootstrap.min.css">
    <link rel="stylesheet" href="./src/bootstrap-theme.min.css">
 
    <link rel="stylesheet" href="http://netdna.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
 

    <link rel="stylesheet" href="./src/bootstrap-navbar-custom.css">
    <link rel="stylesheet" href="./src/scrolling-nav.css">
    <link rel="stylesheet" href="./src/mfp.css">
	<link rel="stylesheet" href="./src/font-awesome-4.7.0/css/font-awesome.min.css">
	
    <link rel="shortcut icon" href="./src/NUS_logo.jpg">
    
    <script async="" src="./src/analytics.js"></script><script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-45156688-2', 'auto');
      ga('send', 'pageview');
    </script>

    <title>Kai Wang</title>
  </head>

  <body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">
<script async defer src="https://buttons.github.io/buttons.js"></script>
    <!-- HEADER -->
      <div class="navbar navbar-custom navbar-fixed-top top-nav-collapse" role="navigation">
        <div class="container">

          <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse">
              <span class="sr-only">Toogle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand page-scroll" href="https://kaiwang960112.github.io/#page-top">Home</a>
          </div>

          <div class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
              <li class="hidden"><a class="page-scroll" href="https://kaiwang960112.github.io/#page-top"></a></li>
              <li class="active"><a class="page-scroll" href="https://kaiwang960112.github.io/#about">About</a></li>
              <li><a class="page-scroll" href="https://kaiwang960112.github.io/#publication">Publications</a></li>
              <li><a class="page-scroll" href="https://kaiwang960112.github.io/#education">Education</a></li>
              <li><a class="page-scroll" href="https://kaiwang960112.github.io/#
		      ">Academic Service</a></li>
              <li><a class="page-scroll" href="https://kaiwang960112.github.io/#awards">Award</a></li>
			  <li><a class="page-scroll" href="https://kaiwang960112.github.io/#work_experience">Work Experience</a></li>
			  
			  <li><a class="page-scroll" href="https://kaiwang960112.github.io/#interest">Interest</a></li>
			  <li><a class="page-scroll" href="https://kaiwang960112.github.io/#friend">Friends</a></li>
            </ul>
          </div>

        </div>

      </div>

    <!-- MAIN CONTENT -->
    
    <section id="home" data-speed="0" data-type="background" class="home-section">
    
      <div class="container profile">
        <div class="row">
        
          <div class="col-md-4 col-xs-12 profile-img">
            <img src="./src/crop_kw.jpg" class="img-respective center-block" alt="Profile image" width="322" ,height="322">
          </div>
        

          <div class="col-md-6 col-xs-12 profile-info">
            <div><span class="english-name">Kai Wang</span>
            <div class="spacer"></div>
            <div class="info-list">
              <div>Research Fellow</div>
              <div>School of Computing</div>
              <div>National University of Singapore</div>
              <div class="email"><b>kai.wang960112[at]gmail[dot]com / kai.wang[at]comp[dot]nus[dot]edu[dot]sg</b></div>
            </div>
            <div class="social-links">
              <a href="https://github.com/kaiwang960112" target="_blank"><i class="fa fa-github-square fa-3x" aria-hidden="true"></i></a>
              <a href="https://scholar.google.com/citations?user=i2II0XIAAAAJ&hl=zh-CN=en" target="_blank"><i class="fa fa-graduation-cap fa-2x" aria-hidden="true"></i></a>
            </div>

          </div>
        </div>
        
      </div>
    
    </div></section>


    <section id="about" class="about-section">

      <div class="container">
        <div class="row">
          <div class="col-md-12 profile-description">
            <h2>About Me </h2>
            <hr>
            <div class="spacer"></div>
		  <!-- -->
	    <p>I am a research fellow in <a href='https://ai.comp.nus.edu.sg/'>HPC-AI Lab</a> at National University of Singapore, working with Prof. <a href='https://www.comp.nus.edu.sg/~youy/'>Yang YOU</a>.</p>
            <p>My doctoral thesis committee is composed of Professor <a href='https://www.chuatatseng.com/'>Tat Seng CHUA</a>, who serves as the Chair, as well as Professor <a href='https://sites.google.com/view/showlab'>Mike SHOU</a> and Professor <a href='https://www.comp.nus.edu.sg/~youy/'>Yang YOU</a>.</p>
            <p>I received my M.S. degree in 2020 from <a href='https://mmlab.siat.ac.cn/'>MMLab@SIAT</a> , supervised by Prof. <a href='https://scholar.google.com/citations?user=gFtI-8QAAAAJ&hl=zh-CN'>Yu Qiao</a> and Assoc. Prof. <a href='https://scholar.google.com/citations?hl=zh-CN&user=7oRD67kAAAAJ&view_op=list_works&sortby=pubdate'>Xiaojiang Peng</a> .</p>
            <p>My research focuses on Parameter Generation and Efficient Machine Learning. I place an emphasis on exploring simple and baseline approaches to gain insights into the workings of deep learning. 
              Until now, my top-5 publications are 
              <a href='https://arxiv.org/pdf/2501.11587'>RPG (arXiv 2025)</a>,
              <a href='https://arxiv.org/pdf/2402.13144.pdf'>p-diff (arXiv 2024)</a>,
              <a href='https://arxiv.org/pdf/2408.12588'>PAB (ICLR-2025)</a>,
              <a href='https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_CAFE_Learning_To_Condense_Dataset_by_Aligning_Features_CVPR_2022_paper.pdf'>CAFE (CVPR-2022)</a>,
              and <a href='https://arxiv.org/pdf/2303.04947.pdf'>InfoBatch (ICLR-2024 Oral)</a>.</p>
	  </p>
          </div>

        </div>
      </div> <!-- end of Description -->
    </section>
    <section id="news" class="news-section">

      <div class="container">
        <div class="row">
          <div class="col-md-12">
            <h2>News</h2>
            <hr>
            <div class="spacer"></div>
            <ul>
    <li><span class="glyphicon"></span> Feb. 2025: <b><a href='https://oahzxl.github.io/PAB/'>Pyramid Attention Broadcast</a></b> was merged into <b><a href='https://huggingface.co/docs/diffusers/main/en/api/cache'>HuggingFace Diffuers</a></b>. Stay tuned! </li> 
    <li><span class="glyphicon"></span> Jan. 2025: Pass the thesis defense!</li> 
		<li><span class="glyphicon"></span> Dec. 2024: <b><a href='https://oahzxl.github.io/Enhance_A_Video/'>Enhance-A-Video</a></b> was merged into <b><a href='https://github.com/kijai/ComfyUI-CogVideoXWrapper'>ComfyUI-Cogvideo</a></b>, <b><a href='https://github.com/logtd/ComfyUI-LTXTricks'>ComfyUI-LTX</a></b>, and <b><a href='https://github.com/kijai/ComfyUI-HunyuanVideoWrapper'>ComfyUI-Hunyuan</a></b>. Many thanks to <b><a href='https://github.com/kijai'>kijai</a></b> üëè! Stay tuned!</li>
		<li><span class="glyphicon"></span> Sep. 2024: <b><a href='https://oahzxl.github.io/PAB/'>Pyramid Attention Broadcast</a></b> was cited by <b><a href='https://ai.meta.com/static-resource/movie-gen-research-paper'>Meta Movie Gen Report</a></b>. Stay tuned! </li> 
		<li><span class="glyphicon"></span> Sep. 2024: Congrats to my coauthors for their papers accepted to NeurIPS-2024!</li> 
		<li><span class="glyphicon"></span> July 2024: <b><a href='https://arxiv.org/pdf/2405.18347'>Dataset Growth</a></b> has been accepted by  <b><font color="Red">ECCV-2024</font></b>. Congrats to my coauthors!</li> 
		<li><span class="glyphicon"></span> May. 2024: <b>Three papers</b> have been accepted by  <b><font color="Red">ICML-2024</font></b>. Congrats to my coauthors!</li> 
		<li><span class="glyphicon"></span> Jan. 2024:<b><a href='https://github.com/henryqin1997/InfoBatch'>InfoBatch</a></b>, the first lossless dynamic data pruning approach, was selected as  <b><font color="Red">Oral Presentation in ICLR-2024.</font></b>. </li> 
		<li><span class="glyphicon"></span> Jan. 2024:<b><a href='https://gzyaftermath.github.io/DATM/'>DATM</a></b>, the first lossless dataset distillation approach, was accepted by  <b><font color="Red">ICLR-2024.</font></b>. </li> 
		<li><span class="glyphicon"></span> Jan. 2024: <b>Four papers</b> have been accepted by  <b><font color="Red">ICLR-2024</font></b>, including One Oral, One Spotlight, and 2 Posters </li> 
		<li><span class="glyphicon"></span> Sep. 2023: <b><a href='https://github.com/RingBDStack/SGDD'>SGDD</a></b>,  <b><a href='https://github.com/Vanint/DatasetExpansion'>GIF</a></b>, and <b><a href='https://github.com/BDeMo/pFedBreD_public'>pFedBreD</a></b> have been accepted by  <b><font color="Red">NeurIPS-2023</font></b>.</li> 
		<li><span class="glyphicon"></span> July 2023: <b><a href='https://github.com/lyq312318224/DREAM'>Dream</a></b>,  <b><a href='https://github.com/magic-research/Dataset_Quantization'>Dataset Quantization</a></b>, and <b><a href='https://github.com/Thunderbeee/ZSCL'>ZSCL</a></b> have been accepted by  <b><font color="Red">ICCV-2023</font></b>.</li> 
		<li><span class="glyphicon"></span> Feb. 2023: <b><a href='https://github.com/xu5zhao/BiCro'>BiCro</a></b> and <b><a href='https://github.com/vimar-gu/MSINet'>MSINet</a></b> have been accepted by  <b><font color="Red">CVPR-2023</font></b>, two papers consider the data issues in AI.</li> 
		<li><span class="glyphicon"></span> Jan. 2023: <b><a href='https://github.com/xyupeng/BETA'>Beta</a></b> was selected as  <b><font color="Red">Spotlight Paper in ICLR-2023</font></b>.</li> 
		<li><span class="glyphicon"></span> Nov. 2022: <b><a href='https://github.com/Huage001/DatasetFactorization'>HaBa</a></b> was selected as  <b><font color="Red">Spotlight Paper in NeurIPS-2022</font></b>.</li> 
		<li><span class="glyphicon"></span> Sep. 2022: <b>One Paper</b> has been accepted by  <b><font color="Red">NeurIPS-2022</font></b>.</li>
		<li><span class="glyphicon"></span> July 2022: <b>One Paper</b> has been accepted by  <b><font color="Red">ECCV-2022</font></b>.</li> 
		<li><span class="glyphicon"></span> Mar. 2022: <b><a href='https://github.com/xyupeng/ContrastiveCrop'>ContrastiveCrop</a></b> was selected as  <b><font color="Red">Oral Presentation in CVPR-2022</font></b>.</li> 
		<li><span class="glyphicon"></span> Mar. 2022: Give a talk in Sun Yat-sen University, invited by Prof. <b><a href='https://lemondan.github.io/'>Xiaodan Liang</a></b>. Slides coming soon.</li> 
		<li><span class="glyphicon"></span> Mar. 2022: Give a talk in ByteDance, invited by Prof. <b><a href='https://sites.google.com/site/jshfeng/'>Jiashi Feng</a></b>. Slides coming soon.</li> 
		<li><span class="glyphicon"></span> Mar. 2022: <b>Five papers</b> have been accepted by  <b><font color="Red">CVPR-2022</font></b>, including two first-author papers, one equal-first-author paper, and one second-author paper.</li> 
		<li><span class="glyphicon"></span> Oct. 2021: Our Team win one <b><font color="Red">Champion</font> and and one <font color="Red">Third Place</font></b> in ICCV-MFR Challenge, one <b><font color="Red">Second Place</font></b> in InsightFace Track.</li> 
		<li><span class="glyphicon"></span> Aug. 2021: One Conference paper has been accepted by <font color="Red">ICCV-MFR-Workshop</font>.</li> 
		<li><span class="glyphicon"></span> May 2021: Got <b><font color="Red">AI Singapore Ph.D. Fellowship!!!!</font></b></li> </li> 
		<li><span class="glyphicon"></span> May 2021:  One Journal paper has been accepted by <b><font color="Red">Transaction on Artificial Intelligence.</font></b></li> </li> 
		<li><span class="glyphicon"></span> Mar. 2021: Got a  <b><font color="Red">NUS Ph.D offer!!!</font></b></li> </li> 
		<li><span class="glyphicon"></span> Feb. 2021: One Journal paper has been accepted by <b><font color="Red">Neurocomputing</font>.</b></li> </li> 
		<li><span class="glyphicon"></span> Jul. 2020: Start my full-time intern at <b><font color="Red">Alibaba DAMO Acadmey</font>.</b></li>
		<li><span class="glyphicon"></span> Jul. 2020: One Conference paper has been accepted by <b><font color="Red">ECCV2020</font>.</b></li>
		<li><span class="glyphicon"></span> May. 2020: One Conference paper has been accepted by <b><font color="Red">ICIP2020</font>.</b></li>
		<li><span class="glyphicon"></span> Feb. 2020: One Conference paper has been accepted by <b><font color="Red">CVPR2020</font>.</b></li>
		<li><span class="glyphicon"></span> Jan. 2020: Start my part-time intern at <b><font color="Red">Huawei Cloud</font>.</b></li>
		<li><span class="glyphicon"></span> Dec. 2019: One Journal paper has been accepted by <b><font color="Red">TIP</font>.</b></li>
		<li><span class="glyphicon"></span> Dec. 2019: One Conference paper has been accepted by <b><font color="Red">AAAI2020</font>.</b></li>
		<li><span class="glyphicon"></span> Dec. 2019: Our team achieve <b><font color="Red">Top 6/2612</font></b> in NAIC Challenge.</li>
		<li><span class="glyphicon"></span> Oct. 2019: Three Conference papers have been accepted by <font color="Red">ICMI-2019</font>.</li>
		<li><span class="glyphicon"></span> Sep. 2019: Our team win the  <b><font color="Red">Champion</font></b> in Huawei Garbege Classification Challenge.</li>
		<li><span class="glyphicon"></span> Aug. 2019: Our team win the  <b><font color="Red">Two Second and One Third Place</font></b> in EmotiW-2019 Challenge.</li>
		<li><span class="glyphicon"></span> Jan. 2019: Our team win the  <b><font color="Red">Champion</font></b> in PEER (Hosted by UC. Berkeley) Challenge.</li>
		<li><span class="glyphicon"></span> Aug. 2018: Our team win the  <b><font color="Red">One Champion and One Second Place</font></b> in EmotiW-2018 Challenge.</li>
		<li><span class="glyphicon"></span> Aug. 2017: Our team win the  <b><font color="Red">One Champion</font></b> in EmotiW-2017 Challenge.</li>
		<li><span class="glyphicon"></span> Some Awards before 2017, you can check out from my CV</li>
            </ul>
            
          </div>

        </div>
      </div> 
    </section>


    <section id="publication" class="publication-section">
      <div class="container">
        <h2>Selected Publications</h2>
        <hr>


<div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/arXiv-2025-RPG.png">
              <img src="./papers/arXiv-2025-RPG.png" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">Scaling Up Parameter Generation: A Recurrent Diffusion Approach</div>
            <div class="author"> <b>Kai Wang<sup>*</sup></b>, Dongwen Tang<sup>*</sup>, Wangbo Zhao, Konstantin Sch√ºrholt, Zhangyang Wang<sup>+</sup>, and Yang You<sup>+</sup> </div> 
            <div class="conf">tech report 2025</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
		<i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/2501.11587" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/NUS-HPC-AI-Lab/Recurrent-Parameter-Generation" target="blank">Code</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://x.com/VictorKaiWang1/status/1881380005118419435" target="blank">Twitter</a>
          </div>
        </div>   
        <br>
        <br>




<div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/enhance-a-video.png">
              <img src="./papers/enhance-a-video.png" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">Enhance-A-Video: Better Generated Video for Free</div>
            <div class="author"> Yang Luo, Xuanlei Zhao, Mengzhao Chen, Kaipeng Zhang, Wenqi Shao<sup>+</sup>, <b>Kai Wang<sup>+</sup></b>, Zhangyang Wang, and Yang You (<font color="Red">Corresponding authors</font>)</div> 
            <div class="conf">tech report 2024</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
		<i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/2502.07508" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/NUS-HPC-AI-Lab/Enhance-A-Video" target="blank">Code</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://x.com/YangL_7/status/1870116980717695243" target="blank">Twitter</a>
          </div>
        </div>   
        <br>
        <br>


	      




	     <!-- <div class="spacer"></div>
<div class="row item">
  <div class="col-md-4 col-sm-6 col-xs-12 item-img">
    <a class="image-popup-no-margins" href="./papers/Dataset_Growth.mp4">
      <video src="./papers/Dataset_Growth.mp4" class="img-thumbnail img-responsive" controls muted autoplay loop></video>
    </a>
  </div>
  <div class="col-md-8 col-sm-6 col-xs-12 item-info">
    <div class="paper">Dataset Growth</div>
    <div class="author"> Ziheng Qin, Zhaopan Xu, et. al,  Hongxun Yao<sup>*</sup>, <b>Kai Wang<sup>*</sup></b>, and Yang You<sup>*</sup> (<font color="Red">Corresponding authors</font>)</div> 
    <div class="conf">ECCV 2024</div> 
    <div class="tag"> 
      <span class="label label-success">Conference</span>
    </div> 
    <i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/2405.18347" target="blank">Paper</a>
    <i class="fa fa-book fa-fw"></i><a href="https://github.com/NUS-HPC-AI-Lab/InfoGrowth" target="blank">Code</a>
    <i class="fa fa-book fa-fw"></i><a href="https://github.com/NUS-HPC-AI-Lab/InfoGrowth" target="blank">Summary</a>
  </div>
</div>   
<br>
<br> -->


	      


	      <div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/arXiv-2024-PAB.png">
              <img src="./papers/arXiv-2024-PAB.png" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">Real-Time Video Generation with Pyramid Attention Broadcast</div>
            <div class="author"> Xuanlei Zhao<sup>*</sup>, Xiaolong Jin<sup>*</sup>, <b>Kai Wang<sup>*+</sup></b>, and Yang You<sup>+</sup> (<font color="Red">Equal contribution and equal advising</font>)</div> 
            <div class="conf">ICLR-2025</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
		<i class="fa fa-book fa-fw"></i><a href="https://oahzxl.github.io/PAB/" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://oahzxl.github.io/PAB/" target="blank">Code</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://x.com/oahzxl/status/1805939975420330298" target="blank">Twitter</a>
          </div>
        </div>   
        <br>
        <br>

	      
<div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/arXiv-2024-SpeeD.png">
              <img src="./papers/arXiv-2024-SpeeD.png" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">A Closer Look at Time Steps is Worthy of Triple Speed-Up for Diffusion Model Training</div>
            <div class="author"> <b>Kai Wang<sup>*</sup></b>, Yukun Zhou<sup>*</sup>, Mingjia Shi<sup>*</sup>, Zhihang Yuan, Yuzhang Shang, Xiaojiang Peng, Hanwang Zhang, and Yang You (<font color="Red">Equal contribution</font>)</div> 
            <div class="conf">arXiv 2024</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
		<i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/2405.17403" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/kaiwang960112/SpeeD" target="blank">Code</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/kaiwang960112/SpeeD" target="blank">Summary</a>
          </div>
        </div>   
        <br>
        <br>


	      


	      
	<div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/arXiv-2024-p-diff.png">
              <img src="./papers/arXiv-2024-p-diff.png" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">	Neural Network Diffusion</div>
            <div class="author"> <b>Kai Wang</b>, Dongwen Tang, Boya Zeng, Yida Yin, Zhaopan Xu, Yukun Zhou, Zelin Zang, Trevor Darrell, Zhuang Liu<sup>*</sup>, and Yang You<sup>*</sup> (<font color="Red">Equal advising</font>)</div> 
            <div class="conf">arXiv 2024</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
		<i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/2402.13144.pdf" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/NUS-HPC-AI-Lab/Neural-Network-Diffusion" target="blank">Code</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://twitter.com/_akhaliq/status/1760136914861019645?s=20" target="blank">Twitter</a>
          </div>
        </div>   
        <br>
        <br>


	      

	<div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/ICLR-2024-InfoBatch.png">
              <img src="./papers/ICLR-2024-InfoBatch.png" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">	InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning</div>
            <div class="author"> Ziheng Qin, <b>Kai Wang<sup>*</sup> </b>, Zangwei Zheng, Jianyang Gu, Xiangyu Peng, Zhaopan Xu, Daquan Zhou, Lei Shang, Baigui Sun, Xuansong Xie, and Yang You (<font color="Red">Project lead and Equal-first author</font>)</div> 
            <div class="conf"> <b><font color="Red">Oral Presentation (1.2%) in </font></b> The Twelfth International Conference on Learning Representations (ICLR) 2024</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
		<i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/2303.04947.pdf" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/NUS-HPC-AI-Lab/InfoBatch" target="blank">Code</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://openreview.net/forum?id=C61sk5LsK6" target="blank">OpenReview</a>
          </div>
        </div>   
        <br>
        <br>


	<div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/ICLR-2024-DATM.png">
              <img src="./papers/ICLR-2024-DATM.png" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">	Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching</div>
            <div class="author">Ziyao Guo, <b>Kai Wang<sup>*</sup> </b>, George Cazenavette, Hui Li, Kaipeng Zhang, and Yang You (<font color="Red">Project lead </font>)</div> 
            <div class="conf"> The Twelfth International Conference on Learning Representations (ICLR) 2024</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
		<i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/2310.05773.pdf" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/NUS-HPC-AI-Lab/DATM" target="blank">Code</a>
		   <i class="fa fa-book fa-fw"></i><a href="https://openreview.net/forum?id=rTBL8OhdhH" target="blank">OpenReview</a>
          </div>
        </div>   
        <br>
        <be>
	      

	<div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/DQ_ICCV_2023.jpg">
              <img src="./papers/DQ_ICCV_2023.jpg" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">	Dataset Quantization</div>
            <div class="author"> Daquan Zhou, <b>Kai Wang<sup>*</sup> </b>, Jianyang Gu<sup>*</sup>, Xiangyu Peng, Dongze Lian, Yifan Zhang, Yang You, and Jiashi Feng (<font color="Red">Equal-first author</font>)</div> 
            <div class="conf">  International Conference on Computer Vision (ICCV), 2023</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
		<i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/2308.10524.pdf" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/magic-research/Dataset_Quantization" target="blank">Code</a>
          </div>
        </div>   
        <br>
        <br>



	<div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/DREAM_ICCV_2023.jpg">
              <img src="./papers/DREAM_ICCV_2023.jpg" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">	DREAM: Efficient Dataset Distillation by Representative Matching</div>
            <div class="author"> Yanqing Liu, Jianyang Gu, <b>Kai Wang<sup>*</sup> </b>, Zheng Zhu, Wei Jiang, and Yang You (<font color="Red">Project Lead</font>)</div> 
            <div class="conf">  International Conference on Computer Vision (ICCV), 2023</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
		<i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/2302.14416.pdf" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/lyq312318224/DREAM" target="blank">Code</a>
          </div>
        </div>   
        <br>
        <br>

		
	      
	      
	<div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/arXiv-2023-DiM.png">
              <img src="./papers/arXiv-2023-DiM.png" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">	DiM: Distilling Dataset into Generative Model</div>
            <div class="author"> <b>Kai Wang</b>, Jianyang Gu, Daquan Zhou, Zheng Zhu, Wei Jiang, and Yang You </div> 
            <div class="conf">  arXiv 2023</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
		<i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/2303.04707.pdf" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/vimar-gu/DiM" target="blank">Code</a>
          </div>
        </div>   
        <br>
        <br>
	     
	      
	      
	<div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/CVPR-2022-CAFE.png">
              <img src="./papers/CVPR-2022-CAFE.png" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">	CAFE: Learning to Condense Dataset by Aligning Features</div>
            <div class="author"> <b>Kai Wang</b>, Bo ZhaoÔºåXiangyu Peng, Zheng Zhu, Shuo Yang, 
		      Shuo Wang, Guan Huang, Hakan Bilen, Xinchao Wang, and Yang You</div> 
            <div class="conf">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
			<i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/2203.01531.pdf" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/kaiwang960112/CAFE" target="blank">Code</a>
          </div>
        </div>   
        <br>
        <br>
	      
       
       <div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/CVPR-2022-FFC.png">
              <img src="./papers/CVPR-2022-FFC.png" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">	An Efficient Training Approach for Very Large Scale Face Recognition</div>
            <div class="author"> <b>Kai Wang</b>, Shuo Wang, Panpan Zhang, Zhipeng Zhou, Zheng Zhu, Xiaobo Wang, Xiaojiang Peng, Baigui Sun, Hao Li, and Yang You </div> 
            <div class="conf">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
		  <i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/2105.10375.pdf" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/tiandunx/FFC" target="blank">Code</a>
          </div>
        </div>   
        <br>
        <br>
	      
     <div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/CVPR-2022-CCROP.png">
              <img src="./papers/CVPR-2022-CCROP.png" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">	Crafting Better Contrastive Views for Siamese Representation Learning</div>
            <div class="author"> Xiangyu Peng, <b>Kai Wang<sup>*</sup> </b>, Zheng Zhu, Mang Wang, and Yang You (<font color="Red">Equal-first author</font>)</div> 
            <div class="conf"> <b><font color="Red">Oral Presentation in </font></b> IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
			<i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/2202.03278.pdf" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/xyupeng/ContrastiveCrop" target="blank">Code</a>
          </div>
        </div>   
        <br>
        <br>
	      
 <div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/CVPR-2020-SCN.png">
              <img src="./papers/CVPR-2020-SCN.png" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">	Suppressing uncertainties for large-scale facial expression recognition</div>
            <div class="author"> <b>Kai Wang</b>, Xiaojiang Peng, Jianfei Yang, Shijian Lu, and Yu Qiao</div> 
            <div class="conf">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020</div> 
            <div class="tag"> 
              <span class="label label-success">Conference</span>
            </div> 
			<i class="fa fa-book fa-fw"></i><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Suppressing_Uncertainties_for_Large-Scale_Facial_Expression_Recognition_CVPR_2020_paper.pdf" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/kaiwang960112/Self-Cure-Network" target="blank">Code</a>
          </div>
        </div>   
        <br>
        <br>
	      
 <div class="spacer"></div>
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12 item-img">
            <a class="image-popup-no-margins" href="./papers/TIP-2020-RAN.png">
              <img src="./papers/TIP-2020-RAN.png" class="img-thumbnail img-responsive">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            <div class="paper">	Region attention networks for pose and occlusion robust facial expression recognition</div>
            <div class="author"> <b>Kai Wang</b>, Xiaojiang Peng, Jianfei Yang, Debin Meng, and Yu Qiao</div> 
            <div class="conf">IEEE Transaction on Image Processing (TIP), 2020</div> 
            <div class="tag"> 
              <span class="label label-primary">Journal</span>
            </div> 
			<i class="fa fa-book fa-fw"></i><a href="https://arxiv.org/pdf/1905.04075.pdf" target="blank">Paper</a>
		  <i class="fa fa-book fa-fw"></i><a href="https://github.com/kaiwang960112/Challenge-condition-FER-dataset" target="blank">Code</a>
          </div>
        </div>   
        <br>
        <br>
	   
        
      </div> <!-- end of Publication  -->

    </section> 

    <section id="education" class="education-section">
      <div class="container">
        <h2>Education</h2>
        <hr>
        <div class="spacer"></div>
		
		<div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12">
            <a href="https://www.nus.edu.sg/" target="_blank">
              <img src="./src/NUS_logo.jpg" style="width:280px;height:140px;" align="center" class="img-responsive edu-img">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            
            <div class="row edu">
              <div class="col-md-12 col-xs-12 edu-info">
                <div class="degree"><b>Ph.D.</b> in Data Science & Machine Learning<br> National University of Singapore, Singapore</div>
                <div class="date">Aug. 2021 - Present</div>
              </div>
            </div>
    
          </div>
        </div>
		
        <div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12">
            <a href="https://www.ucas.ac.cn/" target="_blank">
              <img src="./src/cas.jpeg" style="width:140px;height:140px;" align="center" class="img-responsive edu-img">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            
            <div class="row edu">
              <div class="col-md-12 col-xs-12 edu-info">
                <div class="degree"><b>M.S.</b> in Computer Technology <br> University of Chinese Acadmey of Sciences</div>
                <div class="date">Sep. 2017 - Aug. 2020</div>
              </div>
            </div>
    
          </div>
        </div>
		<div class="row item">
          <div class="col-md-4 col-sm-6 col-xs-12">
            <a href="http://www.bnuz.edu.cn/" target="_blank">
              <img src="./src/bnu.png" style="width:140px;height:140px;" align="center" class="img-responsive edu-img">
            </a>
          </div>
          <div class="col-md-8 col-sm-6 col-xs-12 item-info">
            
            <div class="row edu">
              <div class="col-md-12 col-xs-12 edu-info">
                <div class="degree"><b>B.Eng.</b> in Electrical Engineering and Automation <br> Beijing Normal University, Zhuhai, China</div>
                <div class="date">Sep. 2013 - July 2017</div>
              </div>
            </div>
    
          </div>
        </div>
      </div> <!-- end of Education -->

<section id="academic" class="advising experience">
      <div class="container"> 
        <h2>Advising Experience</h2>
        <hr>
        <div class="spacer"></div>
		
        <h3>Current Research Interns</h3>
        <ul>
            <li><b><a href='https://lizekai-richard.github.io/'>ZeKai Li</a></b> (undergraduate student at NUS).</li>
	    <li><b><a href='https://scholar.google.com/citations?user=9lKm_5IAAAAJ&hl=zh-CN'>Dongwen Tang</a></b> (undergraduate student at Xidian University).</li>
	    <li><b><a href='https://jerryliang24.github.io/'>Zhiyuan Liang</a></b> (undergraduate student at USTC).</li>
        </ul>

        <h3>Alumni</h3>
        <ul>
	    <li><b><a href='https://twitter.com/YuKunZhou9'>Yukun Zhou</a></b> (undergraduate student at Xidian University).</li>
	    <li><b><a href='https://scholar.google.com/citations?user=pHXKrL0AAAAJ&hl=zh-CN'>Tianyi Li</a></b> (Ph.D. student at HKU).</li>
	    <li><b><a href='https://jinxiaolong1129.github.io/'>Xiaolong Jin</a></b> (Ph.D. student at Purdue University).</li>
	    <li><b><a href='https://scholar.google.com/citations?user=FlZSxJMAAAAJ&hl=zh-CN'>Ziyao Guo</a></b> (Ph.D. student at NUS, <b><font color="Red">ICLR-2024</font></b>, <b><font color="Red">ICML-2024</font></b>).</li>
	    <li><b><a href='https://scholar.google.com/citations?hl=zh-CN&user=Y2oqeP0AAAAJ'>Yuchen Zhang</a></b> (incoming Ph.D. student under PKU and Shanghai AI Lab, <b><font color="Red">ICML-2024</font></b>).</li>
	    <li><b><a href='https://scholar.google.com/citations?user=jH54BzoAAAAJ&hl=zh-CN&authuser=1'>Tianle Zhang</a></b> (incoming Ph.D. student at Nanyang Tech. Univ., Singapore, <b><font color="Red">ICML-2024</font></b>).</li>
	    <li><b><a href='https://www.samjs.online/'>Mingjia Shi</a></b> (master student at Sichuan University, <b><font color="Red">NeruIPS-2023</font></b>).</li>
            <li><b><a href='https://scholar.google.com.hk/citations?user=2obvvPoAAAAJ&hl=zh-CN'>Yanqing Liu</a></b> (Ph.D. student at UCSC, <b><font color="Red">ICCV-2023</font></b>).</li>
            <li><b><a href='https://scholar.google.cz/citations?user=STiz5AcAAAAJ&hl=zh-CN'>Beining Yang</a></b> (Ph.D. student at The University of Edinburgh, <b><font color="Red">NeruIPS-2023</font></b>).</li>
        </ul>

        <p><b><font color="Red">(All talents are welcome to send an email to me if you are interested in collaborating on projects related to Data-Centric AI, Parameter Generation, or other promising research directions.)</font></b></p>
      
      </div>
</section>

	    
	
	<section id="academic" class="academic-section">
      <div class="container"> 
        <h2>Academic Service</h2>
        <hr>
        <div class="spacer"></div>
			
			<li><span class="glyphicon"></span>Reviewer of CVPR, ECCV, ICML, NeurIPS, ICCV, AAAI, ICLR</li>
			<li><span class="glyphicon"></span>Reviewer of TIP, TCSVT, TAFFEC, TNNLS</li>
      
         </div>
    </section>
	
    
	
<section id="friend" class="friend-section">
      <div class="container">
        <h2>Friends</h2>
        <hr>
        <div class="spacer"></div>
         <a href="https://marsyang.site/">Jianfei Yang</a> (NTU),
	 <a href="https://huaizhengzhang.github.io/">Huaizheng Zhang</a> (NTU),
	 <a href="https://sijieji.github.io/">Sijie Ji</a> (NTU),
<a href="http://www.zhengzhu.net/">Zheng Zhu</a> (Tsinghua University),
<a href="https://bozhaonanjing.wixsite.com/mysite">Bo Zhao</a> (The University of Edinburgh),      
<a href="https://jiankangdeng.github.io/">Jiankang Deng</a> (Huawei London),
<a href="https://kevin-ssy.github.io/">Shuyang Sun</a> (Oxford University),
<a href="https://kpzhang93.github.io/">Kaipeng Zhang</a> (The University of Tokyo),
<a href="http://luohao.site/">Hao Luo</a> (Alibaba Group),
<a href="https://scholar.google.com/citations?user=KRUTk7sAAAAJ&hl=zh-CN">Xiangyu Peng</a> (NUS),
<a href="https://wangbo-zhao.github.io/">Wangbo Zhao</a> (NUS),
<a href="https://jnjaby.github.io/">Ruicheng Feng</a> (NTU),
<a href="https://junhaozhang98.github.io/">David Junhao Zhang</a> (NUS),
<a href="https://zhengzangw.com/">Zangwei Zheng</a> (NUS),
<a href="https://wangbo-zhao.github.io/">Wangbo Zhao</a> (NUS),
<a href="https://ai.comp.nus.edu.sg/people/yong/">Yong Liu</a> (NUS), 
<a href="https://scholar.google.com/citations?user=lBCCo0EAAAAJ&hl=en">Yaqi Xie</a> (NUS), 
<a href="https://xuefuzhao.github.io/">Fuzhao Xue</a> (NUS)
         </div>
    </section>
	
</div></section>
    <div class="footer">
      <div class="container">
        <div class="row item">
		
        <p>Copyright ¬© Kai Wang 2021</p>
        <!--<p>Template from <a href="http://phoenix104104.github.io">Jason Lai</a></p>
        <!--
        <p class="last-update">
          Last Updated: 
          <script language="JavaScript">
            document.write(document.lastModified);
          </script>
        </p>
		 <div align="center"><a href="http://www.amazingcounters.com"><img border="0" src="http://cc.amazingcounters.com/counter.php?i=3202466&c=9607711" alt="AmazingCounters.com"></a></div>
      </div>
	  
    </div>
	
    <script type="text/javascript" src="./src/jquery-1.11.0.js"></script>
    <script src="./src/bootstrap.min.js"></script>
    <!--
    <script src="//code.jquery.com/jquery-1.11.3.min.js"></script>
    <script src="//code.jquery.com/jquery-migrate-1.2.1.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    -->
    <!-- Scrolling Nav JavaScript -->
    <script src="./src/jquery.easing.min.js"></script>
    <script src="./src/scrolling-nav.js"></script>
    <script src="./src/mfp.js"></script>
    <script type="text/javascript" src="./src/main.js"></script>
	    
    <hr>
    <div id="clustrmaps-widget"></div><script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=268&t=tt&d=32HsWfCBlA3pH7w0_vhA1pzvtzoDkcXu1bg9Hg3yTQo"></script>
    
  

</div></body></html>
